"""
SoulLink Memory Engine â€” ä¸‰å±‚è®°å¿†ç³»ç»Ÿ
ä»å¯¹è¯ä¸­å¼‚æ­¥æå–å…³é”®ä¿¡æ¯ï¼Œå­˜å…¥ MongoDBï¼Œæ³¨å…¥ system promptã€‚

è®°å¿†å±‚çº§:
  permanent (â‰¤10) â€” èº«ä»½/å®¶äºº/å® ç‰©/èŒä¸šç­‰ï¼Œæ°¸ä¸è‡ªåŠ¨åˆ é™¤
  long_term (â‰¤15) â€” é‡è¦ç»å†/åå¥½/ä¹ æƒ¯ï¼Œ90 å¤©æ·¡åŒ–
  short_term (â‰¤5)  â€” è¿‘æœŸäº‹ä»¶/ä¸´æ—¶æƒ…ç»ªï¼Œ14 å¤©è¿‡æœŸ
"""

import os
import re
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from bson import ObjectId

logger = logging.getLogger(__name__)

# ==================== é…ç½® ====================

MAX_PERMANENT = 10
MAX_LONG_TERM = 15
MAX_SHORT_TERM = 5
SHORT_TERM_DAYS = 14
LONG_TERM_DAYS = 90
SYNC_EVERY_N = 5  # æ¯ N æ¬¡æå–åŒæ­¥ä¸€æ¬¡ system prompt

EXTRACTION_PROMPT = """You are a STRICT memory extraction assistant for an AI companion app. Your job is to decide what's worth remembering about the user. Memory slots are LIMITED and precious â€” only store facts that will be useful in FUTURE conversations.

User message: {user_msg}
AI reply: {ai_reply}

Existing memories:
{existing_summary}

=== STRICT RULES ===

1. BE EXTREMELY SELECTIVE. When in doubt, store NOTHING. Empty output is perfectly fine and expected for most conversations.

2. NEVER store any of these (instant reject):
   - Greetings & farewells: ä½ å¥½, æ™šå®‰, æ—©ä¸Šå¥½, goodbye, good night, hi, hey, å†è§, æ‹œæ‹œ, ç¡äº†, èµ·åºŠäº†
   - Real-time data: weather, temperature, Â°F, Â°C, stock prices, sports scores, exchange rates
   - News events: accidents, disasters, elections, celebrity gossip, headlines
   - Timestamps: "ä»Šå¤©", "æ˜¨å¤©", "åˆšæ‰", "ç°åœ¨" â€” these expire immediately
   - Meta-conversation: "æµ‹è¯•AI", "ä½ èƒ½ä¸èƒ½...", "è¯•è¯•çœ‹", testing the AI, asking what AI can do
   - Vague emotions: "å¿ƒæƒ…ä¸å¥½", "æœ‰ç‚¹ç´¯", "æ— èŠ" (too transient to remember)
   - AI's own responses or capabilities â€” only store facts ABOUT THE USER

3. ONLY store facts that pass this test: "Would this fact still be useful to know in 2 weeks?"
   - YES: "ç”¨æˆ·åœ¨æ˜Ÿå·´å…‹å·¥ä½œ" â†’ useful for future conversations
   - YES: "ç”¨æˆ·å…»äº†ä¸€åªå«Mochiçš„çŒ«" â†’ permanent identity fact
   - YES: "ç”¨æˆ·ä¸‹å‘¨è¦æ¬åˆ°çº½çº¦" â†’ important upcoming life event
   - NO:  "ç”¨æˆ·ä»Šå¤©å‡†å¤‡ç¡è§‰" â†’ irrelevant tomorrow
   - NO:  "Riversideä»Šå¤©48Â°F" â†’ expired in hours
   - NO:  "ç”¨æˆ·è¯´äº†æ™šå®‰" â†’ just a greeting
   - NO:  "å¤ªæµ©æ¹–å‘ç”Ÿé›ªå´©" â†’ news, not about the user

4. Store the user's INTEREST, not the data itself:
   - OK:  "ç”¨æˆ·ç»å¸¸å…³æ³¨Riversideå¤©æ°”"
   - BAD: "Riversideä»Šå¤©48Â°Fæœ‰é£"
   - OK:  "ç”¨æˆ·å…³æ³¨åŠ å¯†è´§å¸å¸‚åœº"
   - BAD: "æ¯”ç‰¹å¸ä»Šå¤©æ¶¨äº†5%"

5. Categories (be strict about placement):
   - permanent: real name, family members, pets, job/school, hometown, birthday, nationality â€” things that rarely change
   - long_term: hobbies, food preferences, relationship status, important life plans, recurring habits
   - short_term: ONLY significant upcoming events (travel plans, job interviews, exams) â€” NOT daily trivia

6. Keep each fact under 15 words, in the SAME language as the user's message.

7. If the user corrects old info (e.g. "I changed jobs"), output an update instead of a new memory.

Return ONLY valid JSON:
{{"new_memories": [{{"fact": "...", "type": "permanent|long_term|short_term"}}], "updates": [{{"old_fact": "exact old text", "new_fact": "updated text"}}]}}

If NOTHING worth remembering (this should be the case for most casual messages): {{"new_memories": [], "updates": []}}"""


# ==================== é¢„è¿‡æ»¤ â€” è·³è¿‡ä¸å€¼å¾—æå–çš„æ¶ˆæ¯ ====================

# çŸ­æ¶ˆæ¯æ¨¡å¼ï¼šæ‰“æ‹›å‘¼ã€å‘Šåˆ«ã€å•å­—å›å¤ç­‰
_SKIP_PATTERNS = [
    # ä¸­æ–‡
    r'^(ä½ å¥½|å—¨|å“ˆå–½|hello|hi|hey|å˜¿|åœ¨å—|åœ¨ä¸åœ¨)[\s!ï¼.ã€‚?ï¼Ÿ]*$',
    r'^(æ™šå®‰|æ—©å®‰|æ—©ä¸Šå¥½|åˆå®‰|ä¸‹åˆå¥½|æ™šä¸Šå¥½|good\s*(morning|night|evening))[\s!ï¼.ã€‚~ï½â¤ï¸ğŸ’•ğŸ˜˜ğŸŒ™]*$',
    r'^(æ‹œæ‹œ|å†è§|bye|byebye|see\s*you|å›è§|èµ°äº†|ç¡äº†|å»äº†|ä¸‹æ¬¡è§)[\s!ï¼.ã€‚~ï½]*$',
    r'^(å¥½çš„?|ok|okay|å—¯|å“¦|å“ˆå“ˆ|å‘µå‘µ|å˜»å˜»|è°¢è°¢|thanks?|thank\s*you|ä¸å®¢æ°”|æ²¡äº‹|å¯¹|æ˜¯çš„?)[\s!ï¼.ã€‚]*$',
    r'^(å•Š|å‘ƒ|å””|é¢|å—¯å—¯|å“‡|wow|lol|haha|ğŸ˜‚|ğŸ¤£|â¤ï¸|ğŸ‘|ğŸ’•|ğŸ¥°|ğŸ˜Š|ğŸ˜˜)+[\s!ï¼.ã€‚]*$',
]
_SKIP_COMPILED = [re.compile(p, re.IGNORECASE) for p in _SKIP_PATTERNS]


def _should_skip_extraction(user_msg: str) -> bool:
    """åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦å¤ªçŸ­/å¤ªtrivialï¼Œä¸å€¼å¾—è°ƒ Gemini æå–"""
    msg = user_msg.strip()

    # ç©ºæ¶ˆæ¯
    if not msg:
        return True

    # çº¯ emoji
    if all(ord(c) > 0x1F000 or c in ' \t' for c in msg):
        return True

    # è¿‡çŸ­ä¸”æ— å®è´¨ä¿¡æ¯ï¼ˆ< 4ä¸ªä¸­æ–‡å­—ç¬¦æˆ– < 8ä¸ªè‹±æ–‡å­—ç¬¦ï¼‰
    clean = re.sub(r'[\s!ï¼?ï¼Ÿ.ã€‚,ï¼Œ~ï½]+', '', msg)
    if len(clean) <= 3:
        return True

    # åŒ¹é…è·³è¿‡æ¨¡å¼
    for pattern in _SKIP_COMPILED:
        if pattern.match(msg):
            return True

    return False


# ==================== åç½®è¿‡æ»¤ â€” æ‹¦æˆªåƒåœ¾è®°å¿† ====================

_JUNK_PATTERNS = [
    # å®æ—¶æ•°æ®
    r'(ä»Šå¤©|æ˜¨å¤©|ç°åœ¨|åˆšæ‰|ç›®å‰).{0,10}(æ¸©åº¦|Â°[FC]|åº¦|â„ƒ|â„‰)',
    r'\d+\s*Â°[FC]',
    r'(å¤©æ°”|æ°”æ¸©|é™é›¨|ä¸‹é›¨|ä¸‹é›ª|æœ‰é£|æ™´|å¤šäº‘|é˜´å¤©)',
    # æ–°é—»äº‹ä»¶
    r'(é›ªå´©|åœ°éœ‡|äº‹æ•…|æ´ªæ°´|å°é£|é£“é£|é‡éš¾|æ­»äº¡|ä¼¤äº¡)',
    r'(æ–°é—»|å¤´æ¡|æŠ¥é“|breaking)',
    # æ‰“æ‹›å‘¼/å‘Šåˆ«
    r'^ç”¨æˆ·(è¯´äº†?|æ‰“äº†?)(æ™šå®‰|æ—©å®‰|ä½ å¥½|å†è§|æ‹œæ‹œ)',
    r'(å‡†å¤‡ç¡è§‰|è¦ç¡äº†|å»ç¡äº†|å‡†å¤‡ä¼‘æ¯|going to sleep|going to bed)',
    # å…ƒå¯¹è¯
    r'(æµ‹è¯•AI|è¯•æ¢AI|è€ƒéªŒAI|æµ‹è¯•.*åˆ¤æ–­|è¾¹ç•Œé—®é¢˜|testing)',
    r'ç”¨æˆ·(é—®|è¯¢é—®|æƒ³çŸ¥é“)(AI|äººå·¥æ™ºèƒ½)(èƒ½ä¸èƒ½|æ˜¯å¦|ä¼šä¸ä¼š)',
    # è‚¡ç¥¨/ä»·æ ¼
    r'(è‚¡ä»·|è‚¡ç¥¨|æ¯”ç‰¹å¸|bitcoin|æ¶¨äº†?|è·Œäº†?|ä»·æ ¼)\s*\d',
]
_JUNK_COMPILED = [re.compile(p, re.IGNORECASE) for p in _JUNK_PATTERNS]


def _is_junk_memory(fact: str) -> bool:
    """ä»£ç å±‚å…œåº•ï¼šæ‹¦æˆª Gemini é”™è¯¯æå–çš„åƒåœ¾è®°å¿†"""
    for pattern in _JUNK_COMPILED:
        if pattern.search(fact):
            logger.info(f"[MEMORY] Junk filter blocked: '{fact}'")
            return True
    return False


# ==================== Gemini API è°ƒç”¨ ====================

_gemini_model = None


def _get_gemini_model():
    """å»¶è¿Ÿåˆå§‹åŒ– Gemini æ¨¡å‹"""
    global _gemini_model
    if _gemini_model is None:
        try:
            import google.generativeai as genai
            api_key = os.getenv("GOOGLE_GEMINI_API_KEY")
            if not api_key:
                logger.error("[MEMORY] GOOGLE_GEMINI_API_KEY not set in .env")
                return None
            genai.configure(api_key=api_key)
            _gemini_model = genai.GenerativeModel("gemini-2.5-flash")
            logger.info("[MEMORY] Gemini model initialized")
        except Exception as e:
            logger.error(f"[MEMORY] Failed to init Gemini: {e}")
            return None
    return _gemini_model


def _call_gemini(prompt: str) -> Optional[str]:
    """è°ƒç”¨ Gemini API è¿”å›æ–‡æœ¬å“åº”"""
    model = _get_gemini_model()
    if not model:
        return None
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.warning(f"[MEMORY] Gemini API error: {e}")
        return None


# ==================== è®°å¿†æå– ====================

def extract_memories(user_msg: str, ai_reply: str, existing_memory: Dict) -> Optional[Dict]:
    """
    ä»ä¸€è½®å¯¹è¯ä¸­æå–æ–°è®°å¿†å’Œæ›´æ–°ã€‚
    è¿”å› {"new_memories": [...], "updates": [...]} æˆ– Noneï¼ˆæå–å¤±è´¥ï¼‰
    """
    # æ„å»ºå·²æœ‰è®°å¿†æ‘˜è¦ç»™ LLM å‚è€ƒï¼ˆé¿å…é‡å¤æå–ï¼‰
    existing_summary = _summarize_existing(existing_memory)

    prompt = EXTRACTION_PROMPT.format(
        user_msg=user_msg,
        ai_reply=ai_reply,
        existing_summary=existing_summary or "(none yet)"
    )

    raw = _call_gemini(prompt)
    if not raw:
        return None

    # æ¸…ç†å¯èƒ½çš„ markdown åŒ…è£¹
    text = raw.strip()
    if text.startswith("```"):
        text = text.split("\n", 1)[-1]  # å»æ‰ç¬¬ä¸€è¡Œ ```json
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()

    try:
        result = json.loads(text)
        # éªŒè¯ç»“æ„
        if "new_memories" not in result:
            result["new_memories"] = []
        if "updates" not in result:
            result["updates"] = []

        # åç½®è¿‡æ»¤ï¼šæ‹¦æˆªåƒåœ¾è®°å¿†
        result["new_memories"] = [
            m for m in result["new_memories"]
            if not _is_junk_memory(m.get("fact", ""))
        ]

        return result
    except json.JSONDecodeError as e:
        logger.warning(f"[MEMORY] JSON parse error: {e}, raw: {text[:200]}")
        return None


def _summarize_existing(memory: Dict) -> str:
    """å°†å·²æœ‰è®°å¿†è½¬æˆç®€çŸ­æ‘˜è¦ä¾› LLM å‚è€ƒ"""
    lines = []
    for layer in ["permanent", "long_term", "short_term"]:
        for item in memory.get(layer, []):
            lines.append(f"- [{layer}] {item['fact']}")
    return "\n".join(lines) if lines else ""


# ==================== è®°å¿†åˆå¹¶ ====================

def merge_memories(existing: Dict, extracted: Dict) -> tuple:
    """
    åˆå¹¶æ–°æå–çš„è®°å¿†åˆ°å·²æœ‰è®°å¿†ä¸­ã€‚
    è¿”å› (updated_memory, has_changes)
    """
    now = datetime.utcnow()
    has_changes = False

    # ç¡®ä¿ç»“æ„å®Œæ•´
    for layer in ["permanent", "long_term", "short_term"]:
        if layer not in existing:
            existing[layer] = []

    # 1. å¤„ç†æ›´æ–°ï¼ˆæ›¿æ¢å·²æœ‰è®°å¿†ï¼‰
    for update in extracted.get("updates", []):
        old_fact = update.get("old_fact", "").strip()
        new_fact = update.get("new_fact", "").strip()
        if not old_fact or not new_fact:
            continue

        # åç½®è¿‡æ»¤ï¼šæ›´æ–°å†…å®¹ä¹Ÿè¦æ£€æŸ¥
        if _is_junk_memory(new_fact):
            continue

        found = False
        for layer in ["permanent", "long_term", "short_term"]:
            for item in existing[layer]:
                if item["fact"].strip() == old_fact:
                    item["fact"] = new_fact
                    item["updated_at"] = now
                    found = True
                    has_changes = True
                    logger.info(f"[MEMORY] Updated: '{old_fact}' â†’ '{new_fact}'")
                    break
            if found:
                break

    # 2. æ·»åŠ æ–°è®°å¿†
    for mem in extracted.get("new_memories", []):
        fact = mem.get("fact", "").strip()
        mem_type = mem.get("type", "short_term")
        if not fact:
            continue

        # æ£€æŸ¥é‡å¤
        if _is_duplicate(existing, fact):
            continue

        # ç¡®ä¿ type æœ‰æ•ˆ
        if mem_type not in ("permanent", "long_term", "short_term"):
            mem_type = "short_term"

        entry = {"fact": fact, "created_at": now, "updated_at": now}

        # æ£€æŸ¥ä¸Šé™
        layer = existing[mem_type]
        max_size = {"permanent": MAX_PERMANENT, "long_term": MAX_LONG_TERM, "short_term": MAX_SHORT_TERM}[mem_type]

        if len(layer) >= max_size:
            if mem_type == "permanent":
                logger.warning(f"[MEMORY] Permanent memory full ({MAX_PERMANENT}), skipping: {fact}")
                continue
            else:
                # åˆ é™¤æœ€æ—§çš„
                layer.sort(key=lambda x: x.get("updated_at", x.get("created_at", now)))
                removed = layer.pop(0)
                logger.info(f"[MEMORY] Evicted oldest {mem_type}: '{removed['fact']}'")

        layer.append(entry)
        has_changes = True
        logger.info(f"[MEMORY] Added [{mem_type}]: '{fact}'")

    return existing, has_changes


def _is_duplicate(memory: Dict, new_fact: str) -> bool:
    """ç®€å•æ–‡æœ¬åŒ¹é…æ£€æŸ¥é‡å¤"""
    new_lower = new_fact.lower().strip()
    for layer in ["permanent", "long_term", "short_term"]:
        for item in memory.get(layer, []):
            if item["fact"].lower().strip() == new_lower:
                return True
    return False


# ==================== è¿‡æœŸæ¸…ç† ====================

def cleanup_expired(memory: Dict) -> Dict:
    """æ¸…ç†è¿‡æœŸçš„ short_term å’Œ long_term è®°å¿†"""
    now = datetime.utcnow()

    # short_term: 14 å¤©è¿‡æœŸ
    if "short_term" in memory:
        cutoff = now - timedelta(days=SHORT_TERM_DAYS)
        before = len(memory["short_term"])
        memory["short_term"] = [
            m for m in memory["short_term"]
            if m.get("updated_at", m.get("created_at", now)) > cutoff
        ]
        removed = before - len(memory["short_term"])
        if removed > 0:
            logger.info(f"[MEMORY] Cleaned {removed} expired short_term memories")

    # long_term: 90 å¤©è¿‡æœŸ
    if "long_term" in memory:
        cutoff = now - timedelta(days=LONG_TERM_DAYS)
        before = len(memory["long_term"])
        memory["long_term"] = [
            m for m in memory["long_term"]
            if m.get("updated_at", m.get("created_at", now)) > cutoff
        ]
        removed = before - len(memory["long_term"])
        if removed > 0:
            logger.info(f"[MEMORY] Cleaned {removed} expired long_term memories")

    return memory


# ==================== è®°å¿†æ–‡æœ¬ç”Ÿæˆï¼ˆæ³¨å…¥ promptï¼‰ ====================

def build_memory_text(memory: Dict) -> str:
    """
    å°†è®°å¿†è½¬æˆç®€æ´æ–‡æœ¬å—ï¼Œç”¨äºæ³¨å…¥ system prompt çš„ {{memory}} å ä½ç¬¦ã€‚
    åˆ†å±‚æ˜¾ç¤ºï¼Œè®© AI çŸ¥é“ä¼˜å…ˆçº§ã€‚å¦‚æœæ²¡æœ‰è®°å¿†è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
    """
    sections = []

    perm = memory.get("permanent", [])
    if perm:
        facts = "\n".join(f"- {item['fact']}" for item in perm)
        sections.append(f"[Core â€” always remember]\n{facts}")

    lt = memory.get("long_term", [])
    if lt:
        facts = "\n".join(f"- {item['fact']}" for item in lt)
        sections.append(f"[Important â€” remember for now]\n{facts}")

    # short_term: åªæ³¨å…¥æœ€è¿‘ 3 å¤©çš„ï¼Œé¿å…è¿‡æ—¶ä¿¡æ¯æ±¡æŸ“ prompt
    st = memory.get("short_term", [])
    if st:
        cutoff = datetime.utcnow() - timedelta(days=3)
        recent = [item for item in st if item.get("updated_at", item.get("created_at", datetime.min)) > cutoff]
        if recent:
            facts = "\n".join(f"- {item['fact']}" for item in recent)
            sections.append(f"[Recent â€” may be outdated]\n{facts}")

    if not sections:
        return ""

    header = "# Memories about the user\nUse these naturally in conversation. Core facts are most important.\n"
    return header + "\n\n".join(sections)


# ==================== ä¸»å…¥å£ ====================

def process_memory(user_id: ObjectId, user_msg: str, ai_reply: str):
    """
    å®Œæ•´è®°å¿†å¤„ç†æµç¨‹ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼‰ï¼š
    0. é¢„è¿‡æ»¤ï¼šè·³è¿‡æ‰“æ‹›å‘¼/å‘Šåˆ«ç­‰æ— æ„ä¹‰æ¶ˆæ¯
    1. ä» MongoDB è¯»å–å·²æœ‰è®°å¿†
    2. æ¸…ç†è¿‡æœŸè®°å¿†
    3. è°ƒ Gemini æå–æ–°è®°å¿†
    4. åˆå¹¶åˆ°å·²æœ‰è®°å¿†
    5. å­˜å› MongoDB
    6. æŒ‰é¢‘ç‡åŒæ­¥ system prompt
    """
    from database import db

    # 0. é¢„è¿‡æ»¤ â€” çŸ­æ¶ˆæ¯/æ‰“æ‹›å‘¼/å‘Šåˆ«ç›´æ¥è·³è¿‡ï¼Œçœ Gemini API è°ƒç”¨
    if _should_skip_extraction(user_msg):
        logger.debug(f"[MEMORY] Skipped trivial message: '{user_msg[:50]}'")
        return

    try:
        # 1. è¯»å–ç”¨æˆ·åŠå·²æœ‰è®°å¿†
        user = db.db["users"].find_one({"_id": user_id})
        if not user:
            logger.warning(f"[MEMORY] User {user_id} not found")
            return

        memory = user.get("memory", {
            "permanent": [],
            "long_term": [],
            "short_term": [],
            "extraction_count": 0,
            "last_prompt_sync": None
        })

        # 2. æ¸…ç†è¿‡æœŸ
        memory = cleanup_expired(memory)

        # 3. æå–æ–°è®°å¿†
        extracted = extract_memories(user_msg, ai_reply, memory)
        if not extracted:
            # æå–å¤±è´¥æˆ–æ— ç»“æœï¼Œä»ç„¶æ›´æ–° count
            memory["extraction_count"] = memory.get("extraction_count", 0) + 1
            db.db["users"].update_one(
                {"_id": user_id},
                {"$set": {"memory": memory}}
            )
            return

        # 4. åˆå¹¶
        memory, has_changes = merge_memories(memory, extracted)

        # 5. æ›´æ–°è®¡æ•°å¹¶å­˜å‚¨
        memory["extraction_count"] = memory.get("extraction_count", 0) + 1
        count = memory["extraction_count"]

        db.db["users"].update_one(
            {"_id": user_id},
            {"$set": {"memory": memory}}
        )

        # 6. æŒ‰é¢‘ç‡åŒæ­¥ system promptï¼ˆæœ‰å˜åŒ– ä¸” æ¯ N æ¬¡ï¼‰
        if has_changes and count % SYNC_EVERY_N == 0:
            _sync_prompt(user_id, user)
            memory["last_prompt_sync"] = datetime.utcnow()
            db.db["users"].update_one(
                {"_id": user_id},
                {"$set": {"memory.last_prompt_sync": memory["last_prompt_sync"]}}
            )
            logger.info(f"[MEMORY] Synced prompt for user {user.get('name', '?')} (count={count})")
        elif has_changes:
            logger.info(f"[MEMORY] Changes saved but prompt sync deferred (count={count}, next sync at {count + (SYNC_EVERY_N - count % SYNC_EVERY_N)})")

    except Exception as e:
        logger.error(f"[MEMORY] process_memory error: {e}")
        import traceback
        traceback.print_exc()


def _sync_prompt(user_id: ObjectId, user: Dict):
    """åŒæ­¥ system prompt åˆ° AnythingLLM workspace"""
    try:
        from workspace_manager import WorkspaceManager
        wm = WorkspaceManager()
        result = wm.update_system_prompt(user_id, user["name"])
        if result.get("success"):
            logger.info(f"[MEMORY] Prompt synced successfully")
        else:
            logger.warning(f"[MEMORY] Prompt sync failed: {result.get('error')}")
    except Exception as e:
        logger.error(f"[MEMORY] Prompt sync error: {e}")
